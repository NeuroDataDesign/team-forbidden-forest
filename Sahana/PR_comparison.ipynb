{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following is a demo on the comparison of classifiers in the prescence of high dimensional gaussion noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Specifications\n",
    "\n",
    "The following is modified from scikit learn's example on classifier comparison. \n",
    "Three synthetic datasets are created using the inbuilt functions from scikit learn - make_classification, make_moons and make circles as per the original demo.\\\n",
    "Each input dataset is configured to have 100 samples and 2 dimensions(features) initially.\\\n",
    "During the experiment, we sample gaussion noise of variance values = 0.1, 1, 10 spanning additional noise dimensions from 5 to 1500 in number.\\\n",
    "Each noise dimension of a particular variance value is sampled and concatenated to the sampled input dataset. \\\n",
    "Post this, the data in addition to the noise dimension is split into training and testing data and the three classifiers- Support Vector Machines, Random Forest and KNN are fitted to the data.\n",
    "We compare the accuracies across SVM, RF and KNN with respect to the number of noise dimensions through a plot of \"Accuracy Vs. Noise Dimensions\"\\\n",
    "We expect to see Random Forest outperform SVM and KNN in the presence of high variance - high dimensional noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the classifiers\n",
    "names = [\"SVM\", \"Random Forest\", \"KNN\" ]\n",
    "classifiers = [\n",
    "          svm.SVC(kernel='linear'), \n",
    "          RandomForestClassifier(n_estimators=50, random_state=1, max_features = 'sqrt'),\n",
    "          KNeighborsClassifier(n_neighbors=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the accuracy \n",
    "def fit_predict(train_data, test_data, train_label , test_label):\n",
    "    accuracies = []\n",
    "    for name, model in zip(names, classifiers):\n",
    "        \n",
    "        model.fit(train_data, train_label)\n",
    "        score = model.score(test_data, test_label)\n",
    "        accuracies.append(score)\n",
    "    \n",
    "    SVM_acc = accuracies[0]\n",
    "    RF_acc = accuracies[1]\n",
    "    KNN_acc = accuracies[2]\n",
    "\n",
    "    return SVM_acc,RF_acc,KNN_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for taking input data, sampling noise and appending it\n",
    "def add_noise(data, mu, var, dim):\n",
    "    n = data.shape[0]\n",
    "    noise = np.random.normal(mu, var, size = [n, dim])\n",
    "    data = np.concatenate([data,noise],axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split the data into training & testing and then calculate the accuracies respectively\n",
    "def split_accuracy(train_data, train_label, size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=size)\n",
    "    svm_acc, rf_acc, knn_acc = fit_predict(X_train, X_test, y_train, y_test)\n",
    "    return svm_acc, rf_acc, knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot the 3 different classifier accuracies with respect to the number of noise dimensions.\n",
    "def plotting(x, acc1, acc2, acc3,ax):\n",
    "    ax.plot(x, acc1, color = 'blue', linewidth = 2, marker='o', label=\"SVM\")\n",
    "    ax.plot(x, acc2, color ='red', linewidth = 2, marker='o', label=\"RF\")\n",
    "    ax.plot(x, acc3, color = 'green', linewidth = 2, marker='o', label=\"KNN\")\n",
    "    ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\t 0\n",
      "[[ 0.72110291 -0.19152185]\n",
      " [-0.94130675 -1.46145334]]\n",
      "i\t 1\n",
      "[[ 0.72110291 -0.19152185]\n",
      " [-0.94130675 -1.46145334]]\n",
      "i\t 2\n",
      "[[ 0.72110291 -0.19152185]\n",
      " [-0.94130675 -1.46145334]]\n",
      "i\t 0\n",
      "[[ 0.72841697 -0.49684117]\n",
      " [ 1.1194887  -0.17371589]]\n",
      "i\t 1\n",
      "[[ 0.72841697 -0.49684117]\n",
      " [ 1.1194887  -0.17371589]]\n",
      "i\t 2\n",
      "[[ 0.72841697 -0.49684117]\n",
      " [ 1.1194887  -0.17371589]]\n",
      "i\t 0\n",
      "[[-0.08422485  2.36874286]\n",
      " [-0.06126332  1.02640038]]\n",
      "i\t 1\n",
      "[[-0.08422485  2.36874286]\n",
      " [-0.06126332  1.02640038]]\n",
      "i\t 2\n",
      "[[-0.08422485  2.36874286]\n",
      " [-0.06126332  1.02640038]]\n",
      "i\t 0\n",
      "[[-1.38718113  0.7737874 ]\n",
      " [ 1.57223755 -0.09792843]]\n",
      "i\t 1\n",
      "[[-1.38718113  0.7737874 ]\n",
      " [ 1.57223755 -0.09792843]]\n",
      "i\t 2\n",
      "[[-1.38718113  0.7737874 ]\n",
      " [ 1.57223755 -0.09792843]]\n",
      "i\t 0\n",
      "[[-1.24124298  0.77530551]\n",
      " [ 0.28331753 -1.91028642]]\n",
      "i\t 1\n",
      "[[-1.24124298  0.77530551]\n",
      " [ 0.28331753 -1.91028642]]\n",
      "i\t 2\n",
      "[[-1.24124298  0.77530551]\n",
      " [ 0.28331753 -1.91028642]]\n",
      "i\t 0\n",
      "[[ 0.52133054 -0.5659638 ]\n",
      " [ 0.1124363   0.70666011]]\n",
      "i\t 1\n",
      "[[ 0.52133054 -0.5659638 ]\n",
      " [ 0.1124363   0.70666011]]\n",
      "i\t 2\n",
      "[[ 0.52133054 -0.5659638 ]\n",
      " [ 0.1124363   0.70666011]]\n",
      "i\t 0\n",
      "[[ 0.83998303 -0.37094589]\n",
      " [-0.47940509 -1.5392001 ]]\n",
      "i\t 1\n",
      "[[ 0.83998303 -0.37094589]\n",
      " [-0.47940509 -1.5392001 ]]\n",
      "i\t 2\n",
      "[[ 0.83998303 -0.37094589]\n",
      " [-0.47940509 -1.5392001 ]]\n",
      "i\t 0\n",
      "[[-1.16223162  1.85091568]\n",
      " [-0.91299313  0.58979942]]\n",
      "i\t 1\n",
      "[[-1.16223162  1.85091568]\n",
      " [-0.91299313  0.58979942]]\n",
      "i\t 2\n",
      "[[-1.16223162  1.85091568]\n",
      " [-0.91299313  0.58979942]]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale=0.6)\n",
    "\n",
    "class dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.noise = [None] * 3\n",
    "        self.s = []\n",
    "        self.r = []\n",
    "        self.k = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            self.s.append([j for j in range(8)])\n",
    "            self.r.append([j for j in range(8)])\n",
    "            self.k.append([j for j in range(8)])\n",
    "        \n",
    "scaler = preprocessing.StandardScaler()\n",
    "noise_dims = [0,5,10,100,150,500,1000,1500]\n",
    "data_noise = [0.1, 1, 10]\n",
    "\n",
    "#fig, axes = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(16,16))\n",
    "#lines = [Line2D([0], [0], color='blue', lw=2), Line2D([0], [0], color='red', lw=2), Line2D([0], [0], color='green', lw=2)]\n",
    "\n",
    "\n",
    "for k in range(1):\n",
    "    ds = [dataset()]*3\n",
    "\n",
    "    for d in range(len(noise_dims)):\n",
    "        ds[0].x, ds[0].y = make_classification(n_samples=500,n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1)\n",
    "        rng = np.random.RandomState(2)\n",
    "        ds[0].x += 2 * rng.uniform(size=ds[0].x.shape)\n",
    "            \n",
    "        ds[1].x, ds[1].y = make_moons(n_samples=500,noise=0.3)\n",
    "        \n",
    "        ds[2].x, ds[2].y = make_circles(n_samples=500,noise=0.2, factor=0.5)\n",
    "        \n",
    "        \n",
    "        for i in range(3):\n",
    "            ds[i].x = scaler.fit_transform(ds[i].x)\n",
    "            #This should go through dataset 0,1,2? it's picking up only the last dataset values\n",
    "            print(\"i\\t\", i)\n",
    "            print(ds[i].x[0:2:,])\n",
    "            \n",
    "            for j in range(3):\n",
    "                sa, ra, ka = split_accuracy(add_noise(ds[i].x, 0, data_noise[j], noise_dims[d]), ds[i].y, 0.25)\n",
    "                ds[i].s[j][d] = sa\n",
    "                ds[i].r[j][d] = ra\n",
    "                ds[i].k[j][d] = ka\n",
    "                \n",
    "                \n",
    "#     for i in range(3):\n",
    "#         for j in range(3):\n",
    "#             plotting(noise_dims, ds[i].s[j], ds[i].r[j], ds[i].k[j], axes[i][j])\n",
    "            \n",
    "# axes[2][2].set_xlabel(\"Noise Dimensions\")\n",
    "# axes[2][2].set_ylabel(\"Accuracy\")\n",
    "# axes[2][2].legend(lines, ['SVM', 'RF', 'KNN'])\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
